{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "* Due: 18.2.2016 at noon\n",
    "* Max points: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General rules\n",
    "* Send the source code or the written notes of your answers as an attachment to markus.hartikainen@jyu.fi before the due time\n",
    "* You will get feedback about your answers a week from the due date\n",
    "* From the second week on, the exercises will be given on the previous Wednesday's lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **2 points** Solve optimization problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min \\quad &\\log(x_1^2+1)+x_2^4+x_1x_3\\\\\n",
    "\\text{s.t. }\\quad &x_1^3-x_2^2\\geq 1\\\\\n",
    "& x_1,x_3\\geq 0, \\ x_2\\in\\mathbb R\n",
    "\\end{align}\n",
    "$$\n",
    "using any method that you have available.\n",
    "2. **2 points** Study multiobjective optimization problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min & \\{\\|x-(1,0)\\|^2,\\|x-(0,1)\\|^2\\}\\\\\n",
    "\\text{s.t. }&x\\in \\mathbb R^2.\n",
    "\\end{align}\n",
    "$$\n",
    "Chracterize algeraicly the full set of Pareto optimal solutions.\n",
    "3. **2 points** Calculate the ideal and nadir vectors for the problem of 2. You can use any methods available.\n",
    "4. **2 points** Try to generate a representative set of Pareto optimal solutions using the weighting method for the problem of 2. Compare this set to the set of Pareto optimal solutions from 2. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def ex6task1(x):\n",
    "    return math.log(x[0] ** 2 + 1) + x[1] ** 4 + x[0] * x[2]\n",
    "def ex6constraint1(x):\n",
    "    return x[0] ** 3 - x[1] ** 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bounds = ((0, float(\"inf\")), (-float(\"inf\"), float(\"inf\")), (0, float(\"inf\")))\n",
    "initial_x = [1., 0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.69314718056\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Given optimal  [ 1.  0.  0.]\n",
      "f(x) at optimal  0.69314718056\n",
      "Constraint value at optimal  -1.33226762955e-15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import ad\n",
    "\n",
    "constraints = ({'type': 'ineq',\n",
    "                'fun' : ex6constraint1,\n",
    "                'jac' : ad.gh(ex6constraint1)[0]})\n",
    "\n",
    "res = minimize(\n",
    "    ex6task1,\n",
    "    initial_x, \n",
    "    method='SLSQP',\n",
    "    jac = ad.gh(ex6task1)[0],\n",
    "    constraints = constraints,\n",
    "    bounds = bounds,\n",
    "    options = {'disp' : True})\n",
    "print(\"Given optimal \", res.x)\n",
    "print(\"f(x) at optimal \", ex6task1(res.x))\n",
    "print(\"Constraint value at optimal \", ex6constraint1(res.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How about penalty function method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alpha(x, f):\n",
    "    (_, ieq, eq) = f(x)\n",
    "    return sum([min([0, ieq_j]) ** 2 for ieq_j in ieq]) + sum([eq_k ** 2 for eq_k in eq])\n",
    "def penalized_function(x, f, r):\n",
    "    return f(x)[0] + r * alpha(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.693230\n",
      "         Iterations: 104\n",
      "         Function evaluations: 195\n",
      "Given optimal  [  1.00006057e+00  -4.82302320e-03   2.27404039e-05]\n",
      "f(x) at optimal  0.693230493818\n",
      "Constraint value at optimal  0.000158462259558\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def ex6task1_constrained(x):\n",
    "    return ex6task1(x), [ex6constraint1(x), x[0], x[2]], []\n",
    "\n",
    "res = minimize(\n",
    "    lambda x: penalized_function(x, ex6task1_constrained, 100000),\n",
    "    initial_x,\n",
    "    method = 'Nelder-Mead',\n",
    "    options = {'disp': True})\n",
    "print(\"Given optimal \", res.x)\n",
    "print(\"f(x) at optimal \", ex6task1(res.x))\n",
    "print(\"Constraint value at optimal \", ex6constraint1(res.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts on this; Penalty function method doesn't look too bad actually as the problem is simple and runs fast despite many function evaluations and iterations. Penalty function as a constraint handling mechanism works fine here too. \n",
    "\n",
    "After trying with different starting points, best f(x) I can find is approximately 0.69."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can minimize the first objective function to zero with vector $x = (1, 0)$. The second can be minimized with $x = (0, 1)$, respectively. So, the full set of pareto optimal solutions lie on a line between these two points, which is intuitive as we are calculating the distance of the solution to the two points. This makes the full set of pareto optimal solutions \n",
    "$$\n",
    "\\{x \\in \\mathbb R^2, x_1, x_2\\geq0 \\mid x_1+x_2=1\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z^{ideal}$ is trivially $(0, 0)$ as both objective functions can be minimized to zero with their respective parameter vectors ($(1, 0)$ for the first and $(0, 1)$ for the second)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z^{nadir}$ is $(f_1([0, 1]), f_2([1, 0])) = (\\sqrt{2}, \\sqrt{2})$ as the objective functions achieve these maximum values when parameter vectors are at the opposite extremes of Pareto optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "def ex6fun(x):\n",
    "    return [numpy.linalg.norm(x - numpy.array([1, 0])), numpy.linalg.norm(x - numpy.array([0, 1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def ex6_normalized(x):\n",
    "    z_ideal = [0, 0]\n",
    "    z_nadir = [math.sqrt(2), math.sqrt(2)]\n",
    "    z = ex6fun(x) \n",
    "    return [(zi - zideali) / (znadiri - zideali) for \n",
    "            (zi, zideali, znadiri) in zip(z, z_ideal, z_nadir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import ad\n",
    "def weighting_method(f, w):\n",
    "    points = []\n",
    "    bounds = ((0, 1),(0,1)) #Bounds of the problem\n",
    "    for wi in w:\n",
    "        res = minimize(\n",
    "            #weighted sum\n",
    "            lambda x: sum(np.array(wi) * np.array(f(x))), \n",
    "            [0.5, 0.5], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac = ad.gh(lambda x: sum(np.array(wi) * np.array(f(x))))[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds, options = {'disp' : False})\n",
    "        points.append(res.x)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\lib\\site-packages\\ad\\__init__.py:770: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  lc_wrt_args = [y*x**(y - 1), 0.]\n",
      "C:\\Miniconda3\\lib\\site-packages\\ad\\__init__.py:771: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  qc_wrt_args = [y*(y - 1)*x**(y - 2), 0.]\n",
      "C:\\Miniconda3\\lib\\site-packages\\ad\\__init__.py:84: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lc_wrt_vars[var1] += dh*fdv1\n",
      "C:\\Miniconda3\\lib\\site-packages\\ad\\__init__.py:87: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  qc_wrt_vars[var1] += dh*f.d2(var1) + d2h*fdv1**2\n",
      "C:\\Miniconda3\\lib\\site-packages\\ad\\__init__.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp = dh*f.d2c(var1, var2) + d2h*f.d(var1)*f.d(var2)\n"
     ]
    }
   ],
   "source": [
    "w = np.random.random((100, 2)) #n random weights\n",
    "repr = weighting_method(ex6_normalized, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "m = np.matrix(repr)\n",
    "plt.scatter(m[:, 0], m[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotted, we see basically 2 or 3 solutions found on the line (though many overlapping solutions at the extremes). Looking at the representation variables a lot of the solutions have NaN elements, which also indicates numerical problems while obtaining the results. The warnings during the optimization tell the same story (divide by zero). So as demonstrated during the class, weighting method is not the best one at visualizing the whole Pareto front."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
